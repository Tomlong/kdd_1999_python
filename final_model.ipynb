{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix as confu\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import grid_search\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('kdd_10_per.csv')\n",
    "testing= pd.read_csv('corrected', header=None)\n",
    "attack_list = open('training_attack_types.txt')\n",
    "attack_dic = {}\n",
    "\n",
    "for line in attack_list.readlines():    \n",
    "    detail = line.split(' ')\n",
    "    if len(detail) == 1:\n",
    "        break\n",
    "    attack_type = detail[1][:-1]\n",
    "    attack_name = detail[0]\n",
    "    \n",
    "    if attack_dic.has_key(attack_type):\n",
    "        attack_dic[attack_type].append(attack_name)\n",
    "    else:\n",
    "        attack_dic[attack_type] = []\n",
    "        attack_dic[attack_type].append(attack_name)\n",
    "\n",
    "string_label_columns = ['flag','service','protocol_type'] \n",
    "testing.columns = training.columns\n",
    "#for i in range(len(string_label_columns)):\n",
    "#    del(training[string_label_columns[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_attack_dic = {}\n",
    "test_attack_dic[\"apache2.\"] = 2 \n",
    "test_attack_dic[\"back.\"] = 2 \n",
    "test_attack_dic[\"buffer_overflow.\"] = 3 \n",
    "test_attack_dic[\"ftp_write.\"] = 4 \n",
    "test_attack_dic[\"guess_passwd.\"] = 4 \n",
    "#test_attack_dic[\"httptunnel.\"] = 4 \n",
    "test_attack_dic[\"httptunnel.\"] = 3 \n",
    "test_attack_dic[\"imap.\"] = 4 \n",
    "test_attack_dic[\"ipsweep.\"] = 1 \n",
    "test_attack_dic[\"land.\"] = 2 \n",
    "test_attack_dic[\"loadmodule.\"] = 3 \n",
    "test_attack_dic[\"mailbomb.\"] = 2 \n",
    "test_attack_dic[\"mscan.\"] = 1 \n",
    "test_attack_dic[\"multihop.\"] = 4 \n",
    "#test_attack_dic[\"multihop.\"] = 3 # note that this is a duplicate \n",
    "test_attack_dic[\"named.\"] = 4 \n",
    "test_attack_dic[\"neptune.\"] = 2 \n",
    "test_attack_dic[\"nmap.\"] = 1 \n",
    "test_attack_dic[\"perl.\"] = 3 \n",
    "test_attack_dic[\"phf.\"] = 4 \n",
    "test_attack_dic[\"pod.\"] = 2 \n",
    "test_attack_dic[\"portsweep.\"] = 1 \n",
    "test_attack_dic[\"processtable.\"] = 2 \n",
    "test_attack_dic[\"ps.\"] = 3 \n",
    "test_attack_dic[\"rootkit.\"] = 3 \n",
    "test_attack_dic[\"saint.\"] = 1 \n",
    "test_attack_dic[\"satan.\"] = 1 \n",
    "test_attack_dic[\"sendmail.\"] = 4 \n",
    "test_attack_dic[\"smurf.\"] = 2 \n",
    "test_attack_dic[\"snmpgetattack.\"] = 4 \n",
    "test_attack_dic[\"snmpguess.\"] = 4 \n",
    "test_attack_dic[\"sqlattack.\"] = 3 \n",
    "test_attack_dic[\"teardrop.\"] = 2 \n",
    "test_attack_dic[\"udpstorm.\"] = 2 \n",
    "test_attack_dic[\"warezmaster.\"] = 4 \n",
    "test_attack_dic[\"worm.\"] = 4 \n",
    "test_attack_dic[\"xlock.\"] = 4 \n",
    "test_attack_dic[\"xsnoop.\"] = 4 \n",
    "test_attack_dic[\"xterm.\"] = 3\n",
    "test_attack_dic['normal.'] = 0\n",
    "attack_dic_num = {}\n",
    "attack_dic_num[0] = ['normal']\n",
    "attack_dic_num[2] = attack_dic['dos']\n",
    "attack_dic_num[4] = attack_dic['r2l']\n",
    "attack_dic_num[3] = attack_dic['u2r']\n",
    "attack_dic_num[1] = attack_dic['probe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#anomaly category\n",
    "category_label_binary = []\n",
    "map(lambda label: map(lambda cate: category_label_binary.append(cate) if label in attack_dic_num[cate] else None,attack_dic_num.keys()),training['label'])\n",
    "category_label_binary = np.array(category_label_binary)\n",
    "category_label_binary[np.where((category_label_binary != 0))] = 1\n",
    "\n",
    "print 'done'\n",
    "test_category_label_binary = []\n",
    "map(lambda label: test_category_label_binary.append(test_attack_dic[label]),testing['label'])\n",
    "test_category_label_binary = np.array(test_category_label_binary)\n",
    "test_category_label_binary[np.where((test_category_label_binary != 0))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#attack category\n",
    "category_label = []\n",
    "map(lambda label: map(lambda cate: category_label.append(cate) if label in attack_dic_num[cate] else None,attack_dic_num.keys()),training['label'])\n",
    "category_label = np.array(category_label)\n",
    "#category_label[np.where((category_label != 0))] = 1\n",
    "\n",
    "print 'done'\n",
    "test_category_label = []\n",
    "map(lambda label: test_category_label.append(test_attack_dic[label]),testing['label'])\n",
    "test_category_label = np.array(test_category_label)\n",
    "#test_category_label[np.where((test_category_label != 0))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(category_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15000*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly index\n",
    "training_anomaly_index_array= []\n",
    "for j in range(3,20):\n",
    "    training_index = []\n",
    "    for name in ['dos', 'u2r', 'r2l', 'probe']:\n",
    "        now_attack_type = attack_dic[name]\n",
    "        now_attack_type_dic = {'normal':0}\n",
    "        for i in range(len(now_attack_type)):\n",
    "            now_attack_type_dic[now_attack_type[i]] = i+1\n",
    "    \n",
    "        for now_name in now_attack_type:\n",
    "            #print len(np.where(training['label'] == now_name)[0].tolist())\n",
    "            attack_len = len(np.where(training['label'] == now_name)[0].tolist())\n",
    "            if attack_len > (1000*j):  \n",
    "                #print attack_len     \n",
    "                #training_index = training_index + np.where(training['label'] == now_name)[0][:(j*1000)].tolist()\n",
    "                training_index = training_index + np.where(training['label'] == now_name)[0][np.random.randint(0,attack_len, (j*1000))].tolist()\n",
    "            else:\n",
    "                training_index = training_index + np.where(training['label'] == now_name)[0].tolist()\n",
    "            \n",
    "\n",
    "    training_index = training_index + np.where(category_label == 0)[0][:int(0.05*len(training_index))].tolist()    \n",
    "    training_anomaly_index_array.append(training_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attack index\n",
    "training_attack_index_array = []\n",
    "for i in range(3,15):\n",
    "    training_index = []\n",
    "    for name in ['dos', 'u2r', 'r2l', 'probe']:   \n",
    "        now_attack_type = attack_dic[name]\n",
    "        now_attack_type_dic = {'normal':0}\n",
    "        for j in range(len(now_attack_type)):\n",
    "            now_attack_type_dic[now_attack_type[j]] = j+1\n",
    "    \n",
    "        for now_name in now_attack_type:\n",
    "            attack_len = len(np.where(training['label'] == now_name)[0].tolist())\n",
    "            #print attack_len, attack_len > (i*10000)\n",
    "            if attack_len > (i*1000):  \n",
    "        \n",
    "                training_index = training_index + np.where(training['label'] == now_name)[0][np.random.randint(0,attack_len, i*1000)].tolist()\n",
    "            else:\n",
    "                training_index = training_index + np.where(training['label'] == now_name)[0].tolist()\n",
    "           \n",
    "    training_attack_index_array.append(training_index)\n",
    "\n",
    "testing_index = np.where(test_category_label != 0)[0].tolist() \n",
    "training_key_index = np.where(category_label != 0)[0].tolist()\n",
    "#training_index = training_index + np.where(category_label == 0)[0][:len(training_index)*1].tolist()\n",
    "#testing_index = np.where(test_category_label == 1)[0].tolist() + np.where(test_category_label == 2)[0][:10000].tolist() \\\n",
    "#                + np.where(test_category_label == 3)[0].tolist() + np.where(test_category_label == 4)[0][:5000].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly key\n",
    "str_combination_anomaly = []\n",
    "map(lambda x: str_combination_anomaly.append((x[0]+'_'+x[1]+'_'+x[2])) if (x[0]+'_'+x[1]+'_'+x[2]) not in str_combination_anomaly else None,training[string_label_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attack type key\n",
    "str_combination_attack = []\n",
    "map(lambda x: str_combination_attack.append((x[0]+'_'+x[1]+'_'+x[2])) if (x[0]+'_'+x[1]+'_'+x[2]) not in str_combination_attack else None,training.iloc[training_key_index][string_label_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly key sort\n",
    "pro_ser_flag_count_anomaly = {}\n",
    "for x in str_combination_anomaly:\n",
    "    pro_ser_flag_count_anomaly[x] = 0\n",
    "for line in training[string_label_columns].values:\n",
    "    key = line[0]+'_'+line[1]+'_'+line[2]\n",
    "    pro_ser_flag_count_anomaly[key] = pro_ser_flag_count_anomaly[key] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attack key sort\n",
    "pro_ser_flag_count_attack = {}\n",
    "for x in str_combination_attack:\n",
    "    pro_ser_flag_count_attack[x] = 0\n",
    "for line in training.iloc[training_key_index][string_label_columns].values:\n",
    "    key = line[0]+'_'+line[1]+'_'+line[2]\n",
    "    pro_ser_flag_count_attack[key] = pro_ser_flag_count_attack[key] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomlay top key \n",
    "sorted_dic_anomaly = sorted(pro_ser_flag_count_anomaly.iteritems(), key=lambda (k,v): (v,k),reverse=True)\n",
    "new_string_columns_anomaly = []\n",
    "new_string_columns_dic_anomaly = {}\n",
    "loc_value = 0\n",
    "for string in sorted_dic_anomaly:\n",
    "    if (string[1] > 1) & (len(new_string_columns_anomaly) < 100):\n",
    "        new_string_columns_anomaly.append(string[0])\n",
    "        new_string_columns_dic_anomaly[string[0]] = loc_value\n",
    "        loc_value = loc_value+1\n",
    "    else:\n",
    "        new_string_columns_anomaly.append('others')\n",
    "        new_string_columns_dic_anomaly['others'] = loc_value\n",
    "        break\n",
    "inv_new_string_columns_dic_anomaly = {v: k for k, v in new_string_columns_dic_anomaly.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attack top key \n",
    "sorted_dic_attack = sorted(pro_ser_flag_count_attack.iteritems(), key=lambda (k,v): (v,k),reverse=True)\n",
    "new_string_columns_attack = []\n",
    "new_string_columns_dic_attack = {}\n",
    "loc_value = 0\n",
    "for string in sorted_dic_attack:\n",
    "    if (string[1] > 1) & (len(new_string_columns_attack) < 100):\n",
    "        new_string_columns_attack.append(string[0])\n",
    "        new_string_columns_dic_attack[string[0]] = loc_value\n",
    "        loc_value = loc_value+1\n",
    "    else:\n",
    "        new_string_columns_attack.append('others')\n",
    "        new_string_columns_dic_attack['others'] = loc_value\n",
    "        break\n",
    "inv_new_string_columns_dic_attack = {v: k for k, v in new_string_columns_dic_attack.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly column\n",
    "training_anomaly_copy = training.copy()\n",
    "testing_anomaly_copy = testing.copy()\n",
    "for column_name in new_string_columns_anomaly:\n",
    "    training_anomaly_copy[column_name] = np.zeros(len(training))\n",
    "    testing_anomaly_copy[column_name] = np.zeros(len(testing))\n",
    "string_vector_anomaly = np.zeros([len(training_anomaly_copy),len(new_string_columns_anomaly)])\n",
    "testing_string_vector_anomlay = np.zeros([len(testing_anomaly_copy),len(new_string_columns_anomaly)])\n",
    "string_vector_loc_anomaly = []\n",
    "testing_string_vector_loc_anomaly = []\n",
    "map(lambda x: string_vector_loc_anomaly.append(new_string_columns_dic_anomaly[(x[0]+'_'+x[1]+'_'+x[2])]) if (x[0]+'_'+x[1]+'_'+x[2]) in new_string_columns_anomaly \\\n",
    "    else string_vector_loc_anomaly.append(new_string_columns_dic_anomaly['others']) ,training_anomaly_copy[string_label_columns].values)\n",
    "map(lambda x: testing_string_vector_loc_anomaly.append(new_string_columns_dic_anomaly[(x[0]+'_'+x[1]+'_'+x[2])]) if (x[0]+'_'+x[1]+'_'+x[2]) in new_string_columns_anomaly \\\n",
    "    else testing_string_vector_loc_anomaly.append(new_string_columns_dic_anomaly['others']) ,testing_anomaly_copy[string_label_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attack column\n",
    "training_attack_copy = training.copy()\n",
    "testing_attack_copy = testing.copy()\n",
    "for column_name in new_string_columns_attack:\n",
    "    training_attack_copy[column_name] = np.zeros(len(training))\n",
    "    testing_attack_copy[column_name] = np.zeros(len(testing))\n",
    "string_vector_attack = np.zeros([len(training_attack_copy),len(new_string_columns_attack)])\n",
    "testing_string_vector_attack = np.zeros([len(testing_attack_copy),len(new_string_columns_attack)])\n",
    "string_vector_loc_attack = []\n",
    "testing_string_vector_loc_attack = []\n",
    "map(lambda x: string_vector_loc_attack.append(new_string_columns_dic_attack[(x[0]+'_'+x[1]+'_'+x[2])]) if (x[0]+'_'+x[1]+'_'+x[2]) in new_string_columns_attack \\\n",
    "    else string_vector_loc_attack.append(new_string_columns_dic_attack['others']) ,training_attack_copy[string_label_columns].values)\n",
    "map(lambda x: testing_string_vector_loc_attack.append(new_string_columns_dic_attack[(x[0]+'_'+x[1]+'_'+x[2])]) if (x[0]+'_'+x[1]+'_'+x[2]) in new_string_columns_dic_attack \\\n",
    "    else testing_string_vector_loc_attack.append(new_string_columns_dic_attack['others']) ,testing_attack_copy[string_label_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_value(training_normal_numpy, key, loc):\n",
    "    training_normal_numpy[loc][key+38] = 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly delete\n",
    "for i in range(len(string_label_columns)):   \n",
    "    del(training_anomaly_copy[string_label_columns[i]])\n",
    "    del(testing_anomaly_copy[string_label_columns[i]])\n",
    "del training_anomaly_copy['label']\n",
    "del testing_anomaly_copy['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#attack delete\n",
    "for i in range(len(string_label_columns)):\n",
    "    del(training_attack_copy[string_label_columns[i]])\n",
    "    del(testing_attack_copy[string_label_columns[i]])\n",
    "del training_attack_copy['label']\n",
    "del testing_attack_copy['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#anomaly replace\n",
    "training_numpy_anomaly = training_anomaly_copy.values\n",
    "testing_numpy_anomaly = testing_anomaly_copy.values\n",
    "map(lambda i: replace_value(training_numpy_anomaly, string_vector_loc_anomaly[i], i),range(len(training_anomaly_copy)))\n",
    "map(lambda i: replace_value(testing_numpy_anomaly, testing_string_vector_loc_anomaly[i],i),range(len(testing_anomaly_copy)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attack replace\n",
    "training_numpy_attack = training_attack_copy.values\n",
    "testing_numpy_attack = testing_attack_copy.values\n",
    "map(lambda i: replace_value(training_numpy_attack, string_vector_loc_attack[i], i),range(len(training_attack_copy)))\n",
    "map(lambda i: replace_value(testing_numpy_attack, testing_string_vector_loc_attack[i], i),range(len(testing_attack_copy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_transform(training_numpy, testing_numpy, index, pca_dim, training_copy):\n",
    "    \n",
    "    min_max = preprocessing.MinMaxScaler()\n",
    "    min_max.fit(training_numpy)\n",
    "    x_scaled = min_max.fit_transform(training_numpy[index])\n",
    "    testting_x_scaled = min_max.transform(testing_numpy)\n",
    "    training_norm = pd.DataFrame(x_scaled, columns = training_copy.columns)\n",
    "    testing_norm = pd.DataFrame(testting_x_scaled, columns = training_copy.columns)\n",
    "    \n",
    "    pca_model = PCA(n_components=pca_dim)\n",
    "    training_pca_value = pca_model.fit_transform(training_norm)\n",
    "    testing_pca_value = pca_model.transform(testing_norm)\n",
    "    return (training_pca_value, testing_pca_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    }
   ],
   "source": [
    "#anomaly training \n",
    "n_estimators = 10\n",
    "start = time.time()\n",
    "svc = SVC(C=pow(10,4))\n",
    "anomoly_model = OneVsOneClassifier(BaggingClassifier(svc, n_estimators=n_estimators), n_jobs=-1)\n",
    "(training_pca_value_anomaly, testing_pca_value_anomaly) = pca_transform(training_numpy_anomaly, testing_numpy_anomaly, training_anomaly_index_array[0],25, training_anomaly_copy)\n",
    "anomoly_model.fit(training_pca_value_anomaly, category_label_binary[training_anomaly_index_array[0]])\n",
    "anomaly_result = anomoly_model.predict(testing_pca_value_anomaly)\n",
    "anomaly_index = np.where(anomaly_result == 1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    }
   ],
   "source": [
    "#attack training \n",
    "n_estimators = 10\n",
    "start = time.time()\n",
    "svc = SVC(C=pow(10,4))\n",
    "attack_model = OneVsRestClassifier(BaggingClassifier(svc, n_estimators=n_estimators), n_jobs=-1)\n",
    "(training_pca_value_attack, testing_pca_value_attack) = pca_transform(training_numpy_attack, testing_numpy_attack, training_attack_index_array[8],5, training_attack_copy)\n",
    "attack_model.fit(training_pca_value_attack, category_label[training_attack_index_array[8]])\n",
    "anomaly_result[anomaly_index] = attack_model.predict(testing_pca_value_attack[anomaly_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93239215635841033"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(anomaly_result == test_category_label) / float(len(anomaly_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46015,      5,    284,      7,     83],\n",
       "       [   636,   3893,    825,    149,    105],\n",
       "       [  1130,    167, 228256,      5,   3932],\n",
       "       [   656,      8,    106,     17,    249],\n",
       "       [ 12156,     93,    382,     50,  11820]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confu(anomaly_result, test_category_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46015,    379],\n",
       "       [ 14578, 250057]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confu(anomaly_result, test_category_label_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3893,    871,    151,    115],\n",
       "       [   169, 228410,      5,   3943],\n",
       "       [     8,    106,     18,    261],\n",
       "       [    96,    466,     54,  11870]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confu(attack_model.predict(testing_pca_value_attack[testing_index]), test_category_label[testing_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311029, 250436)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attack_model.predict(testing_pca_value_attack)), len(test_category_label[testing_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97506348927470488"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_model.score(testing_pca_value_attack[testing_index],test_category_label[testing_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95191123657279542"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(anomaly_result == test_category_label_binary) / float(len(anomaly_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
